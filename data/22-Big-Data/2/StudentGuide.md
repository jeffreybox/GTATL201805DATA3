## Unit 22.2 - Big Data In The Cloud

### Overview

* Today's class will continue to build on Pyspark DataFrames using ZEPL.

* The goal today is to demonstrate how Natural Language Processing works by building a Big Data processing pipeline that is used to train a Naive Bayes Spam Detector.

### Class Objectives

* Students will be able to explain why NLP is necessary for a big data toolkit.
* Students will be able to apply transformations resulting from NLP data processing to PySpark DataFrames.
* Students will be able to explain and utilize PySpark text processing methods like tokenization, stop words, n-grams, term and document frequency.
* Students will be able to describe example steps in an NLP data processing pipeline.

- - -

### Activities Preview

* **PySpark NLP Tokens**

* Instructions:

  * [README.md](Activities/03-Stu_Pyspark_NLP_Tokens/README.md)

* **Food Review Stopwords**

* Instructions:

  * [README.md](Activities/05-Stu_Pyspark_NLP_Stopwords/README.md)

* **PySpark NLP TD-IDF with HashingTF**

* Instructions:

  * [README.md](Activities/07-Stu_Pyspark_NLP_HashingTF/README.md)

- - -

### Copyright

Trilogy Education Services Â© 2018. All Rights Reserved.
